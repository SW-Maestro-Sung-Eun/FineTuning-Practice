{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23TOba33L4qf",
        "outputId": "c8ec96d0-4848-4a4c-d02b-411bafe80d4c"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knSjbKzZRDS-"
      },
      "source": [
        "# **Mount**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEYDl4HORIde",
        "outputId": "aae31163-109f-429a-9ad2-f5a94c8dc021"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTCE9SjtRaKy",
        "outputId": "7883d9af-5c1f-4da2-b3e8-3e15fdd5ad46"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "folder = \"Colab Notebooks\"\n",
        "project_dir = \"PROJECT\"\n",
        "\n",
        "base_path = Path(\"/content/gdrive/My Drive/\")\n",
        "project_path = base_path / folder / project_dir\n",
        "os.chdir(project_path)\n",
        "for x in list(project_path.glob(\"*\")):\n",
        "    if x.is_dir():\n",
        "        dir_name = str(x.relative_to(project_path))\n",
        "        os.rename(dir_name, dir_name.split(\" \", 1)[0])\n",
        "print(f\"현재 디렉토리 위치: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hda8GHssR031"
      },
      "source": [
        "# **SetUp and Download FFHQ model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "wofCIeBq6t8f",
        "outputId": "7d2e9ec0-2652-4f15-db4b-1797fa1865fc"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.10.0+cu113 torchvision==0.11.0+cu113 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1ZiNvdqB8aN",
        "outputId": "a80eae49-da1e-4fd8-de17-81d02a77c44e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"Torch version:{}\".format(torch.__version__))\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))\n",
        "\n",
        "!python -V\n",
        "!nvcc -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SV8uTDn4E-8",
        "outputId": "78e0dac3-3cab-4edf-e2a2-7425eeead674"
      },
      "outputs": [],
      "source": [
        "# git clone\n",
        "\n",
        "!git clone https://github.com/happy-jihye/Cartoon-StyleGan2.git\n",
        "os.chdir(f'./Cartoon-StyleGan2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKhHQYfmUiVr",
        "outputId": "44b76025-e28b-41c9-d76d-dd36be1e787a"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from utils import imshow, tensor2image\n",
        "\n",
        "!pip install git+https://github.com/n-CLAIR/nsml-local\n",
        "!pip install ftfy regex tqdm ninja gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "4LK4iW1ct-b6",
        "outputId": "d4706bb3-a2b5-4a96-8a4c-15c7e14d5e8c"
      },
      "outputs": [],
      "source": [
        "from utils import download_pretrained_model\n",
        "\n",
        "download_pretrained_model(False, \"ffhq256.pt\")\n",
        "\n",
        "# fine-tuning 대비하여 backup 만들기\n",
        "\"\"\"\n",
        "    if not os.path.isdir('networks'):\n",
        "        os.makedirs('networks')\n",
        "    from gdown import download as drive_download\n",
        "\n",
        "    url = \"https://drive.google.com/uc?id=1PQutd-JboOCOZqmd95XWxWrO8gGEvRcO\"\n",
        "    networkfile = os.path.join('networks', \"ffhq256.pt\")\n",
        "    drive_download(url, networkfile, quiet=False)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGetzmKuHAL3"
      },
      "source": [
        "# **Generate Random Images using FFHQ model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS9sjPRGsvzc"
      },
      "outputs": [],
      "source": [
        "from model import Generator\n",
        "\n",
        "device='cuda'\n",
        "main_path = Path(f\"{os.getcwd()}\")\n",
        "\n",
        "network1 = 'ffhq256'  \n",
        "network1 = torch.load(main_path / f\"networks/{ network1 }.pt\" ) # parameter 가져와서 network1에 저장\n",
        "g1 = Generator(256, 512, 8, channel_multiplier=2).to(device) # StyleGAN model 만들기\n",
        "g1.load_state_dict(network1[\"g_ema\"], strict=False) # model에 parameter 전달\n",
        "trunc1 = g1.mean_latent(4096) # 4096배  randn으로 생성하고 평균값을 저장 => 정규분포의 평균에 가까워지고 이상치 없어짐\n",
        "\n",
        "outdir = 'results'\n",
        "if not os.path.isdir(f'{outdir}'):\n",
        "   os.makedirs(main_path / f'asset/{outdir}', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "eo8xWbyl39R6",
        "outputId": "d1c1c5e6-c3f7-4f51-d617-795193d81564"
      },
      "outputs": [],
      "source": [
        "# 이미지 생성\n",
        "# shape가 1 * 14 * 512인 이유, get_latent의 의미는 모르겠음..\n",
        "with torch.no_grad():\n",
        "\n",
        "    # 임의의 FFHQ 이미지를 생성하는 latent 생성\n",
        "    latent1 = torch.randn(1, 14, 512, device=device)  # 1 * 14 * 512의 정규분포 latent 생성\n",
        "    latent1 = g1.get_latent(latent1)  # latent를 g1(FFHQ)에 적용할 수 있도록 변형\n",
        "\n",
        "    # 입력 latent를 가지고 이미지 생성\n",
        "    imgs_gen1, _ = g1(\n",
        "        [latent1],\n",
        "        input_is_latent=True,\n",
        "        truncation=0.7,\n",
        "        truncation_latent=trunc1,\n",
        "        swap=False,\n",
        "        swap_layer_num=0,\n",
        "        randomize_noise=False,\n",
        "    )\n",
        "\n",
        "    # 이미지 보여주기\n",
        "    imshow(tensor2image(imgs_gen1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HSG1kwNcOpi"
      },
      "source": [
        "# **Fine-tuning FFHQ to Disney_StructureLoss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wxu1XL8c1FQ",
        "outputId": "8c6eafe7-37f9-4263-cfd6-c6fec636b0de"
      },
      "outputs": [],
      "source": [
        "# run.py라고 생각했지만, run.py는 압축된 lmdb를 사용할 경우에 하는 것(아님 말구)\n",
        "# prepare_data.py로 이미지를 lmdb dataset으로 변경해야 함\n",
        "# ./IMAGE 내부에 데이터셋 폴더를 삽입 후 실행하면 ./DATA에 dataset 생성\n",
        "\n",
        "!python prepare_data.py --out ./DATA/KOREAN --size 128,256,512 ./IMAGE/KOREAN_IMAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v6VtzN5VjPl",
        "outputId": "4ea8c41a-45c4-4690-ab42-918fc36f02e3"
      },
      "outputs": [],
      "source": [
        "# colab pro는 다른 gpu를 사용하기 때문에 torch/cuda 버전에서 1.8.0+cu111 수행 불가능(RuntimeError 발생)\n",
        "# 그렇다고 1.12.0(default)를 사용하면 colab free에서와 같은 오류가 발생\n",
        "# 그래서 그 중간 어딘가의 버전을 사용해서 어떠한 오류도 발생하지 않도록 함(1.10.0+cu113)\n",
        "# %pip install torch==1.10.0+cu113 torchvision==0.11.0+cu113 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "!python train.py --batch=2 --ckpt=./networks/ffhq256.pt --structure_loss=2 --freezeD=3 --augment --path=./DATA/KOREAN"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "FineTuning_cartoonStyleGAN2.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
